{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSdDnfFf3D6F",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTs0cumk3D6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import pandas as pd"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pitsRHb3D6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "0dYd9AqU3D6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "660d11af-dd20-42b1-9196-ac3461c42591"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>-99</td>\n",
              "      <td>14379</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>14380</td>\n",
              "      <td>17171</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>17172</td>\n",
              "      <td>20372</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>20373</td>\n",
              "      <td>30346</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CYMBELINE</td>\n",
              "      <td>30347</td>\n",
              "      <td>30364</td>\n",
              "      <td>CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...                                                   \n",
              "1                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...\n",
              "2                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "3            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "4                            CYMBELINE  ...  CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvoYgtS43D6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \" \".join(data)\n",
        "\n",
        "\n",
        "\n",
        "chars = list(set(text))\n",
        "\n",
        "char_int = {c:i for i, c in enumerate(chars)}\n",
        "int_char = {i: c for i, c in enumerate(chars)}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOn7CZ9r3D6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "20d6c057-dde3-4b32-b47d-b1dd411ae254"
      },
      "source": [
        "int_char"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Z',\n",
              " 1: '_',\n",
              " 2: 'E',\n",
              " 3: '9',\n",
              " 4: '|',\n",
              " 5: '%',\n",
              " 6: 'a',\n",
              " 7: '5',\n",
              " 8: '$',\n",
              " 9: 'F',\n",
              " 10: 'f',\n",
              " 11: '`',\n",
              " 12: '6',\n",
              " 13: '&',\n",
              " 14: 'z',\n",
              " 15: '!',\n",
              " 16: 'u',\n",
              " 17: 'T',\n",
              " 18: '0',\n",
              " 19: 'b',\n",
              " 20: '‘',\n",
              " 21: 'A',\n",
              " 22: ':',\n",
              " 23: '’',\n",
              " 24: 'î',\n",
              " 25: 'â',\n",
              " 26: '8',\n",
              " 27: ')',\n",
              " 28: '*',\n",
              " 29: '“',\n",
              " 30: '(',\n",
              " 31: '-',\n",
              " 32: 'à',\n",
              " 33: 'H',\n",
              " 34: '”',\n",
              " 35: 'Æ',\n",
              " 36: '1',\n",
              " 37: 'R',\n",
              " 38: 'G',\n",
              " 39: 'o',\n",
              " 40: 't',\n",
              " 41: ',',\n",
              " 42: '4',\n",
              " 43: 'ê',\n",
              " 44: 'N',\n",
              " 45: 'y',\n",
              " 46: 'W',\n",
              " 47: 'O',\n",
              " 48: 'Q',\n",
              " 49: '\"',\n",
              " 50: 'i',\n",
              " 51: '\\\\',\n",
              " 52: 'B',\n",
              " 53: '.',\n",
              " 54: 'Y',\n",
              " 55: ' ',\n",
              " 56: '?',\n",
              " 57: 'K',\n",
              " 58: ';',\n",
              " 59: '}',\n",
              " 60: ']',\n",
              " 61: 'é',\n",
              " 62: '7',\n",
              " 63: 'p',\n",
              " 64: 'œ',\n",
              " 65: 'É',\n",
              " 66: 'j',\n",
              " 67: \"'\",\n",
              " 68: 'k',\n",
              " 69: 'e',\n",
              " 70: 's',\n",
              " 71: 'J',\n",
              " 72: 'V',\n",
              " 73: '@',\n",
              " 74: 'D',\n",
              " 75: 'L',\n",
              " 76: 'æ',\n",
              " 77: 'w',\n",
              " 78: 'q',\n",
              " 79: '/',\n",
              " 80: '—',\n",
              " 81: 'm',\n",
              " 82: 'n',\n",
              " 83: 'U',\n",
              " 84: 'M',\n",
              " 85: 'g',\n",
              " 86: 'x',\n",
              " 87: '3',\n",
              " 88: 'd',\n",
              " 89: 'h',\n",
              " 90: '\\t',\n",
              " 91: 'S',\n",
              " 92: 'r',\n",
              " 93: 'l',\n",
              " 94: 'I',\n",
              " 95: 'v',\n",
              " 96: '2',\n",
              " 97: 'ç',\n",
              " 98: 'C',\n",
              " 99: 'X',\n",
              " 100: 'c',\n",
              " 101: '[',\n",
              " 102: 'P',\n",
              " 103: 'è'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX0zNDHT3D6r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6e347c5e-df74-4bc7-d4ef-e00845771d28"
      },
      "source": [
        "maxlen = 25\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = []\n",
        "next_char = []\n",
        "\n",
        "for i in range(0, len(encoded)-maxlen, step):\n",
        "    sequences.append(encoded[i:i+maxlen])\n",
        "    next_char.append(encoded[i+maxlen])\n",
        "    \n",
        "print(sequences[:1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 36, 55, 55, 9, 92]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNDhXNpZ3D6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "30fe6aca-cd41-44bb-9deb-e56015661a45"
      },
      "source": [
        "for i in sequences[0]:\n",
        "  print(int_char[i])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "1\n",
            " \n",
            " \n",
            "F\n",
            "r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv4JrmBy3D61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeIpep5q3D66",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b7a86ecd-8cc5-49d9-8646-2519d46458ca"
      },
      "source": [
        "next_char[0], int_char[next_char[0]]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39, 'o')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jTkhDhX3D6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFhk_IOA3D7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cHxPJne3D7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JrTJQGB3D7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t, char] = 1\n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MW8NfW13D7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "60b0d5a3-07bd-4958-b5bb-3fbd056ba075"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1111149, 25, 104)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbPyp6d53D7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "e1cb8c7a-dcbb-43e6-f842-e29290b48e40"
      },
      "source": [
        "x[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmO7FiBt3D7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits = False)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY6jsTVz3D7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    LSTM(32, input_shape=(maxlen, len(chars))),\n",
        "    Dense(len(chars), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss=loss, optimizer='adam')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhy_t4c43D7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTqj_lzl3D7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from numpy import random\n",
        "import sys\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoBQ4e3D3D7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "2f096075-655a-40d9-c86d-650df67b25a9"
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=2,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "34722/34724 [============================>.] - ETA: 0s - loss: 1.8772\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"us far forth. By accident\"\n",
            "us far forth. By accidenten; for     A not                                        My stat-stapp I much will wibe; Asseatt? One then tense, if oul due, Jonrichter: Wear a     heresby and hor, the Moll-a meeppele; And the if you werriggly what mast if whenit! O gougle not bettaur?  BELESS. My leck it,     shored—servet her the fall this with othal-if of as the refeck bughing.   HOLRIBAND LLUFFO. I and hin yoush now     Stra\n",
            "34724/34724 [==============================] - 144s 4ms/step - loss: 1.8772\n",
            "Epoch 2/2\n",
            "34717/34724 [============================>.] - ETA: 0s - loss: 1.8506\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \" and fair, Anticipating t\"\n",
            " and fair, Anticipating the bliting lote;   [_Exouftle have and strundst’s to presurcelin, he amad contherians.  MOPHILIZEPO. The pare sobly me serar-in befmeace brust firy Dut pracuss, frath duparice, Greact. COTHULET. I reines there trong; the evierd colve deet be inthurch complece shall you yoce a doad rreved as thine Drae, in trine; At wile and wove I had king truse of thad usurk, wis the derind’s resmy they how theer\n",
            "34724/34724 [==============================] - 144s 4ms/step - loss: 1.8506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5a3817d5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWqjSbbc3Hnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11z0c6gt3LoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e6e75681-4afb-4c42-ea09-0d62e5a49eab"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 5555770 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A-xXuub3OzS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2e85da8e-f56a-4295-a664-44f09f521362"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WHdZ_u23Q7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XcWSbHx3TVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "088db75f-c885-4273-80fe-2b03811bfa30"
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " \n",
            " \n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nJ60E6s3w6-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "6a6c6e9f-ef11-4568-c329-3280930e770a"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'                    1  From fairest creatures we desire increase, That thereby beauty’s rose might ne'\n",
            "'ver die, But as the riper should by time decease, His tender heir might bear his memory: But thou con'\n",
            "'tracted to thine own bright eyes, Feed’st thy light’s flame with self-substantial fuel, Making a fami'\n",
            "'ne where abundance lies, Thy self thy foe, to thy sweet self too cruel: Thou that art now the world’s'\n",
            "' fresh ornament, And only herald to the gaudy spring, Within thine own bud buriest thy content, And, '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQiIYTb134DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp223oFW39Ve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "144995a0-5523-4d0c-d7f0-643134eb741b"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  '                    1  From fairest creatures we desire increase, That thereby beauty’s rose might n'\n",
            "Target data: '                   1  From fairest creatures we desire increase, That thereby beauty’s rose might ne'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXd_prqh3_cu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c71c75a7-4fab-4da8-e769-bc43fed1fd2d"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RyHdA3L4FZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNRdX5oJ4HdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0Q6BW_nPVjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -rf \"training_checkpoints\""
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_8hk4CD4IvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p6n42n-4KCA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "22790643-fb1c-4b1c-f76c-a5c2b6f23547"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 104) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-xva1o24M3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0KIBFRg4Sy2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "0800b6b4-1d9b-4493-e009-a07c6b221f9f"
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " 'es err.   [_Exeunt King, Bertram, Helena, Lords, and Attendants._]  LAFEW. Do you hear, monsieur? A '\n",
            "\n",
            "Next Char Predictions: \n",
            " ';]sGçî—*[œ`)@|OÆ\\\\Rî)n*L/uED|qfç1}GrFÉ\\tTFnP/dâNlW\\tcZ]M%m”!GOQc\\\\\\\\?eàcyD7.d_D\"\"klhUèÆj_]M:“dq/—Bæà;4l[’'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnekqYAf4WJ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5a319171-70e7-4b00-c767-526987d8b9f2"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 104)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.644499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwQNT86N4cuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0qxgadw4fPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zEpp54y4hfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=10\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgoVe2A74jLW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "5506deda-19f3-4820-cb40-a7754cedaf02"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "859/859 [==============================] - 52s 61ms/step - loss: 1.9838\n",
            "Epoch 2/10\n",
            "859/859 [==============================] - 52s 61ms/step - loss: 1.4321\n",
            "Epoch 3/10\n",
            "859/859 [==============================] - 52s 61ms/step - loss: 1.3377\n",
            "Epoch 4/10\n",
            "859/859 [==============================] - 52s 61ms/step - loss: 1.2925\n",
            "Epoch 5/10\n",
            "859/859 [==============================] - 52s 61ms/step - loss: 1.2627\n",
            "Epoch 6/10\n",
            "859/859 [==============================] - 52s 61ms/step - loss: 1.2399\n",
            "Epoch 7/10\n",
            "859/859 [==============================] - 52s 61ms/step - loss: 1.2211\n",
            "Epoch 8/10\n",
            "859/859 [==============================] - 52s 61ms/step - loss: 1.2061\n",
            "Epoch 9/10\n",
            "859/859 [==============================] - 52s 61ms/step - loss: 1.1932\n",
            "Epoch 10/10\n",
            "859/859 [==============================] - 52s 61ms/step - loss: 1.1820\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NblMlUo04kWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VglDEZHD6-Gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 5000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = .5\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0eXJrgH7Bvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "d958bf7e-8e96-4012-d4cb-49227c8400a2"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "print(generate_text(model, start_string=u\"KING \"))\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KING HENRY. What say you to him?   SPEED. The gods the man that thou art as full of them they are.                      Exit                                                                               Exit  SCENE II. The state I think that thou dost forth,     And then the heavens to thee, and rare not called me to the death of all these days.     A blushing cursed sight!                                                                                                         Exeunt PROTEUS and Tranio Emilia the two offers the business to their silent poison.                                   Exeunt PROTEUS      Sweet brother, I will not have thee a servant to her eyes.                                        Exit MARCUS, and attendants                                                                                                                                                                                                                                                                                                                                    Exeunt  SCENE II. The same. A Room in the Palace.   Enter Cleopatra to the COUNTREYMAN What is the matter?         BORACHIO.       I pray thee, lady, I will not to my back.     The colour cannot hold the infant form of love,     When they are created on the children of the death of love.     I will not touch the walls of my desire is mine,     Then who shall not be sad sick of my head     As I see what they are return'd and sleep.     Are you best to be whip?   SILVIA. Alas, poor soul, the gods are fall'n off them.                                                                                                                                                         Exit                                                                                                                                Exeunt ALCIBIADES      He that doth doubt the sun she lives.     What will you hear him sit, and then the place shall chance to cry.                                                                                                           [A plain blushing of the plain]   PROTEUS. Ay, but what think you, my lord?   TIMON. What said she hath been this thing that your blessing makes a man than the cause of the deed!     What say you to be so dear as I am a soldier than my breast.                          Exit   COSTARD. Is this the word?         DON JOHN.       If I do so, I will not change this work     With our discourse of his age, but stopp'd,     And when the cloud the old record of all the bed When they no more than the forest of the state Where the sport is that she swears he shall never love her.                                                                                 Exit  SCENE II. A Room in Olivia’s House.  ACT III  SCENE I. The same. A Room in the palace.   Enter Clown and Attendants.  DUKE. What say'st thou, man?   CORIOLANUS. What, will you love me?   TIMON. What say'st thou that shall I desire you to her so long?     And then I bid you hear the start of mine     Which makes you justice of my love.     What says my lord?   FIRST MURDERER. And I will go     To set them up to the consent of our soldiers,     And that which stands in vain, sir, the true love and discontent     To hear the break of honour, to be from the sea.     What can the slave of mine, this service is no more to be the day.     What should you not have seen, and this same save your pity,     And so will I rest to the clock.     My hand hath sent to be the chamber of the state     To hear the morning leaves of the man doth shine   Which the next war shall stain the start of heart     She is the proceeding of the prime of honour in the matter for the people of her mortal father;     And with you to behold the prison a great company     To the tender time of nature bear the fact     With all the persons of the world.     My lord, let it be constant as a piece of sovereignty.     I ever saw him downe in the peril of her bearing.     What says my lord?   LAUNCE. Nay, that determine on the ballad makes me, and then do me good.     What shall be so bold to be to my body to his love,     The person of his father’s matter thence: He leave him to answer man’s painted butts A merry riast that the pale dog is made to be your cause.   [_Exeunt._]  SCENE III. The same. A Room in the Palace.   Enter Clowne, and the rest of the Count Olympus.  FRIAR LAWRENCE. Sometimes the world will take us. I will be as set the trumpet sounds, And make me live in her some pen to take a child.   [_Exit_.]  SCENE II. The same. A room in the Castle.  ACT II Scene I. Another part of the state where lies of mercy, Shall be as from the world to lose his face with him.  POLIXENES. If you will make a strange thing for your father’s house, Which sometime like a creature and the turtle of the world.                                                                                                                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixITGuuDOVE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_-eOMDArt_O",
        "colab_type": "text"
      },
      "source": [
        "KING HENRY. \\\n",
        "What say you to him?   \n",
        "\n",
        "SPEED. \\\n",
        "The gods the man that thou art as full of them they are.                      Exit                                                                               \n",
        "Exit  \n",
        "\n",
        "SCENE II. \n",
        "The state I think that thou dost forth,     And then the heavens to thee, and rare not called me to the death of all these days.     A blushing cursed sight!                                                                                                         Exeunt \n",
        "\n",
        "PROTEUS and Tranio Emilia the two offers the business to their silent poison.                                   Exeunt \n",
        "\n",
        "PROTEUS\\\n",
        "      Sweet brother, I will not have thee a servant to her eyes.                                        Exit MARCUS, and attendants                                                                                                                                                                                                                                                                                                                                    Exeunt  SCENE II. \n",
        "The same. A Room in the Palace.   \n",
        "      \n",
        "Enter Cleopatra to the COUNTREYMAN What is the matter?         \n",
        "\n",
        "BORACHIO.      \\\n",
        " I pray thee, lady, I will not to my back.     The colour cannot hold the infant form of love,     When they are created on the children of the death of love.     I will not touch the walls of my desire is mine,     Then who shall not be sad sick of my head     As I see what they are return'd and sleep.     Are you best to be whip?   SILVIA. Alas, poor soul, the gods are fall'n off them.                                                                                                                                                         Exit                                                                                                                                Exeunt \n",
        " \n",
        " ALCIBIADES  \\  \n",
        " He that doth doubt the sun she lives.     What will you hear him sit, and then the place shall chance to cry.                                                                                                           [A plain blushing of the plain]   PROTEUS. Ay, but what think you, my lord?   TIMON. What said she hath been this thing that your blessing makes a man than the cause of the deed!     What say you to be so dear as I am a soldier than my breast.                          Exit   COSTARD. Is this the word?         DON JOHN.       If I do so, I will not change this work     With our discourse of his age, but stopp'd,     And when the cloud the old record of all the bed When they no more than the forest of the state Where the sport is that she swears he shall never love her.                                                                                 Exit  SCENE II. A Room in Olivia’s House.  ACT III  SCENE I. The same. A Room in the palace.   Enter Clown and Attendants.  DUKE. What say'st thou, man?   CORIOLANUS. What, will you love me?   TIMON. What say'st thou that shall I desire you to her so long?     And then I bid you hear the start of mine     Which makes you justice of my love.     What says my lord?   FIRST MURDERER. And I will go     To set them up to the consent of our soldiers,     And that which stands in vain, sir, the true love and discontent     To hear the break of honour, to be from the sea.     What can the slave of mine, this service is no more to be the day.     What should you not have seen, and this same save your pity,     And so will I rest to the clock.     My hand hath sent to be the chamber of the state     To hear the morning leaves of the man doth shine   Which the next war shall stain the start of heart     She is the proceeding of the prime of honour in the matter for the people of her mortal father;     And with you to behold the prison a great company     To the tender time of nature bear the fact     With all the persons of the world.     My lord, let it be constant as a piece of sovereignty.     I ever saw him downe in the peril of her bearing.     What says my lord?   LAUNCE. Nay, that determine on the ballad makes me, and then do me good.     What shall be so bold to be to my body to his love,     The person of his father’s matter thence: He leave him to answer man’s painted butts A merry riast that the pale dog is made to be your cause.   [_Exeunt._]  SCENE III. The same. A Room in the Palace.   Enter Clowne, and the rest of the Count Olympus.  FRIAR LAWRENCE. Sometimes the world will take us. I will be as set the trumpet sounds, And make me live in her some pen to take a child.   [_Exit_.]  SCENE II. The same. A room in the Castle.  ACT II Scene I. Another part of the state where lies of mercy, Shall be as from the world to lose his face with him.  POLIXENES. If you will make a strange thing for your father’s house, Which sometime like a creature and the turtle of the world.                                                                                                                                    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOUJ2IVf7FWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 64,
      "outputs": []
    }
  ]
}